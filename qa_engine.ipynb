{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c515de6b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/roche-logo-blue.png\" alt=\"Roche logo\" style=\"float: right;\" width=\"150\" />\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "# Building a Q&A engine with LangChain and open-source LLMs\n",
    "## Marek Grzenkowicz\n",
    "\n",
    "#### September 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a698d5f5",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## About Roche\n",
    "\n",
    "![Key Roche Informatics hubs](images/about-roche.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2265f8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Large Language Models did not appear out of nowhere\n",
    "\n",
    "### Natural language processing (NLP)\n",
    "\n",
    "- Standardized tasks (question answering, summarization, sentiment analysis, ...)\n",
    "- Evaluation benchmarks\n",
    "- **Leaderboards**\n",
    "- Word and sentence **embeddings** (word2vec, GloVe, fastText, ELMo, BERT, ...)\n",
    "\n",
    "### Machine learning\n",
    "\n",
    "- Neural networks\n",
    "- Deep learning\n",
    "- CUDA\n",
    "- Transformer architecture\n",
    "- Attention (ML technique)\n",
    "- Reinforced learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3068c119",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Goals\n",
    "\n",
    "1. Implement an LLM application without deep NLP knowledge\n",
    "2. Develop and run it locally, instead of making API calls to a cloud-hosted model\n",
    "3. Use an open-source model\n",
    "4. Create a prototype with an actual business problem in mind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0def2e66",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tools\n",
    "\n",
    "- [LangChain](https://python.langchain.com/docs/get_started/introduction.html) - framework for developing applications powered by LLMs\n",
    "- [Hugging Face Hub](https://huggingface.co/models) - repository of pre-trained language models\n",
    "  - [Transformers](https://huggingface.co/docs/transformers/index) - downloading the models\n",
    "- [lmsys/fastchat-t5-3b-v1.0](https://huggingface.co/lmsys/fastchat-t5-3b-v1.0) - compact, open-source LLM from [lmsys.org](https://lmsys.org) \n",
    "- [ChromaDB](https://www.trychroma.com) - embedding database (vector store)\n",
    "- [Jupyter Notebook](https://jupyter.org/) with the [RISE](https://github.com/damianavila/RISE) extension - IDE with a slideshow feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f7334c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why the `lmsys/fastchat-t5-3b-v1.0` model?\n",
    "\n",
    "- GPU + 4GB memory - 1B parameters at best\n",
    "- CPU + 32GB RAM - 3B parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c7e20a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- [Open LLM leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard) âž¡ [`CobraMamba/mamba-gpt-3b-v3`](https://huggingface.co/CobraMamba/mamba-gpt-3b-v3) claims to surpass some 12B models\n",
    "  - but it is slow âž¡ [Open LLM performace leaderboard](https://huggingface.co/spaces/optimum/llm-perf-leaderboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d957d6e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "- [lmsys/fastchat-t5-3b-v1.0](https://huggingface.co/lmsys/fastchat-t5-3b-v1.0)\n",
    "  - _A commercial-friendly, compact, yet powerful chat assistant_\n",
    "  - The first model to actually generate any response on my laptop in reasonable time ðŸŽ‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee1ac86",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Some duct tape first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2e4dd33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T11:10:01.376655Z",
     "start_time": "2023-09-01T11:10:01.371671Z"
    },
    "execution": {
     "iopub.execute_input": "2023-08-17T21:41:02.423021Z",
     "iopub.status.busy": "2023-08-17T21:41:02.421305Z",
     "iopub.status.idle": "2023-08-17T21:41:02.437203Z",
     "shell.execute_reply": "2023-08-17T21:41:02.431892Z",
     "shell.execute_reply.started": "2023-08-17T21:41:02.422912Z"
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use with care! important warnings may get hidden\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbd4edbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T11:10:01.389669Z",
     "start_time": "2023-09-01T11:10:01.380411Z"
    },
    "execution": {
     "iopub.execute_input": "2023-08-16T22:06:50.604289Z",
     "iopub.status.busy": "2023-08-16T22:06:50.601671Z",
     "iopub.status.idle": "2023-08-16T22:06:50.619156Z",
     "shell.execute_reply": "2023-08-16T22:06:50.616908Z",
     "shell.execute_reply.started": "2023-08-16T22:06:50.604128Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://github.com/chroma-core/chroma/blob/main/chromadb/__init__.py#L57\n",
    "\n",
    "import sys\n",
    "__import__(\"pysqlite3\")\n",
    "sys.modules[\"sqlite3\"] = sys.modules.pop(\"pysqlite3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517f00e4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Load a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5e02bdd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T11:16:37.638574Z",
     "start_time": "2023-09-01T11:16:37.633203Z"
    },
    "execution": {
     "iopub.execute_input": "2023-08-16T22:06:50.623104Z",
     "iopub.status.busy": "2023-08-16T22:06:50.621944Z",
     "iopub.status.idle": "2023-08-16T22:06:50.640917Z",
     "shell.execute_reply": "2023-08-16T22:06:50.637588Z",
     "shell.execute_reply.started": "2023-08-16T22:06:50.623017Z"
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "035dd36a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T11:10:29.770325Z",
     "start_time": "2023-09-01T11:10:01.402027Z"
    },
    "execution": {
     "iopub.execute_input": "2023-08-16T22:06:50.645364Z",
     "iopub.status.busy": "2023-08-16T22:06:50.644624Z",
     "iopub.status.idle": "2023-08-16T22:07:33.764232Z",
     "shell.execute_reply": "2023-08-16T22:07:33.714360Z",
     "shell.execute_reply.started": "2023-08-16T22:06:50.645309Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device has 1 GPUs available. Provide device={deviceId} to `from_model_id` to use availableGPUs for execution. deviceId is -1 (default) for CPU and can be a positive integer associated with CUDA device id.\n"
     ]
    }
   ],
   "source": [
    "model_id, task = \"lmsys/fastchat-t5-3b-v1.0\", \"text2text-generation\"\n",
    "\n",
    "# model will be downloaded on first use and cached in ~/.cache/huggingface/hub/\n",
    "\n",
    "model = HuggingFacePipeline.from_model_id(\n",
    "    model_id=model_id,\n",
    "    task=task,\n",
    "    model_kwargs={\n",
    "        \"temperature\": 0,\n",
    "        \"max_length\": 1000\n",
    "    },\n",
    "    device=-1,  # CPU\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aecfba",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Initialize an LLM chain and start asking questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "356e652b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T11:10:29.849942Z",
     "start_time": "2023-09-01T11:10:29.800161Z"
    },
    "execution": {
     "iopub.execute_input": "2023-08-16T22:07:33.872300Z",
     "iopub.status.busy": "2023-08-16T22:07:33.858476Z",
     "iopub.status.idle": "2023-08-16T22:07:34.086456Z",
     "shell.execute_reply": "2023-08-16T22:07:34.082581Z",
     "shell.execute_reply.started": "2023-08-16T22:07:33.864984Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "template_text = \"\"\"\n",
    "{question}\n",
    "\"\"\"\n",
    "template = PromptTemplate(template=template_text, input_variables=[\"question\"])\n",
    "\n",
    "llm_chain = LLMChain(llm=model, prompt=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca4756f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T11:11:40.948915Z",
     "start_time": "2023-09-01T11:10:29.853063Z"
    },
    "execution": {
     "iopub.execute_input": "2023-08-16T22:07:34.093984Z",
     "iopub.status.busy": "2023-08-16T22:07:34.093054Z",
     "iopub.status.idle": "2023-08-16T22:08:23.115323Z",
     "shell.execute_reply": "2023-08-16T22:08:23.114319Z",
     "shell.execute_reply.started": "2023-08-16T22:07:34.093904Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> Sheryl  Crow  is  an  American  singer,  songwriter,  and  actress.  She  is  best  known  for  her  role  as  the  lead  singer  and  lead  guitarist  of  the  rock  band  The  Band wagon,  and  for  her  role  as  the  lead  singer  and  lead  guitarist  of  the  alternative  rock  band  The  Mamas  and  the  Papas.  Crow  has  also  been  a  member  of  the  band  The  Mamas  and  the  Papas  since  its  formation  in  1995.\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain(\"Who is Sheryl Crow?\")[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aafabb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Prompt engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3863d1ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T11:11:40.956490Z",
     "start_time": "2023-09-01T11:11:40.951752Z"
    },
    "execution": {
     "iopub.execute_input": "2023-08-16T22:08:23.120133Z",
     "iopub.status.busy": "2023-08-16T22:08:23.119666Z",
     "iopub.status.idle": "2023-08-16T22:08:23.127261Z",
     "shell.execute_reply": "2023-08-16T22:08:23.125549Z",
     "shell.execute_reply.started": "2023-08-16T22:08:23.120104Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "template_text = \"\"\"\n",
    "Provide brief answers, use 10 words or less.\n",
    "{question}\n",
    "\"\"\"\n",
    "template = PromptTemplate(template=template_text, input_variables=[\"question\"])\n",
    "\n",
    "llm_chain = LLMChain(llm=model, prompt=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1be847d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T11:11:43.789294Z",
     "start_time": "2023-09-01T11:11:40.960184Z"
    },
    "execution": {
     "iopub.execute_input": "2023-08-16T22:08:23.144759Z",
     "iopub.status.busy": "2023-08-16T22:08:23.139118Z",
     "iopub.status.idle": "2023-08-16T22:08:26.141136Z",
     "shell.execute_reply": "2023-08-16T22:08:26.139836Z",
     "shell.execute_reply.started": "2023-08-16T22:08:23.144710Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> Singer-songwriter'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain(\"Who is Sheryl Crow?\")[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2743b4e8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Easy questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8c8ce7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T11:11:45.248229Z",
     "start_time": "2023-09-01T11:11:43.791131Z"
    },
    "execution": {
     "iopub.execute_input": "2023-08-16T22:08:26.146251Z",
     "iopub.status.busy": "2023-08-16T22:08:26.144220Z",
     "iopub.status.idle": "2023-08-16T22:08:28.416205Z",
     "shell.execute_reply": "2023-08-16T22:08:28.414969Z",
     "shell.execute_reply.started": "2023-08-16T22:08:26.146142Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> Europe'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain(\"Who is Poland located?\")[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f13f29e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T11:11:52.741068Z",
     "start_time": "2023-09-01T11:11:45.255026Z"
    },
    "execution": {
     "iopub.execute_input": "2023-08-16T22:08:28.441585Z",
     "iopub.status.busy": "2023-08-16T22:08:28.440090Z",
     "iopub.status.idle": "2023-08-16T22:08:35.085948Z",
     "shell.execute_reply": "2023-08-16T22:08:35.084869Z",
     "shell.execute_reply.started": "2023-08-16T22:08:28.441507Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> Bialowieza Forest is a protected forest in Poland.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain(\"What is Bialowieza Forest?\")[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca50ed8e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Harder questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f28f639",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T11:11:57.520547Z",
     "start_time": "2023-09-01T11:11:52.743068Z"
    },
    "execution": {
     "iopub.execute_input": "2023-08-16T22:08:35.093745Z",
     "iopub.status.busy": "2023-08-16T22:08:35.092959Z",
     "iopub.status.idle": "2023-08-16T22:08:40.537052Z",
     "shell.execute_reply": "2023-08-16T22:08:40.535729Z",
     "shell.execute_reply.started": "2023-08-16T22:08:35.093666Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> \"Birch Tree\"'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain(\"What does the name 'Bialowieza' mean in English?\")[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6066e8c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T11:12:09.875125Z",
     "start_time": "2023-09-01T11:11:57.523059Z"
    },
    "execution": {
     "iopub.execute_input": "2023-08-16T22:08:40.539606Z",
     "iopub.status.busy": "2023-08-16T22:08:40.538716Z",
     "iopub.status.idle": "2023-08-16T22:08:50.661029Z",
     "shell.execute_reply": "2023-08-16T22:08:50.659823Z",
     "shell.execute_reply.started": "2023-08-16T22:08:40.539565Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<pad> The Tsar's Trail is a 900 mile long trail that begins in Moscow and ends in St. Petersburg.\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain(\"What's the length of the Tsar's Trail and where does it begin?\")[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5045560d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What now?\n",
    "\n",
    "# Should I fine-tune the base mode? ðŸ¤”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15671b76",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Embeddings and  cosine similarity\n",
    "\n",
    "![cosine similarity in 2D](./images/vectors-cos-sim-500.png)\n",
    "\n",
    "The actual embedding spaces have **100s of dimensions**! ðŸ¤¯\n",
    "\n",
    "Source: https://github.com/grzenkom/do-androids-read/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5321677",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Arithmetic of word vectors\n",
    "\n",
    "\\begin{equation}\n",
    "\\LARGE{\\mathit{ v_{parent} + v_{woman} \\approx v_{x} }}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565a48e4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![sum of \"parent\" and \"woman\" vectors](./images/vector-mother.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7a39a6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\\begin{equation}\n",
    "\\LARGE{\\mathit{ v_{seawater} - v_{salt} \\approx v_{x} }}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c20367a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![difference of \"seawater\" and \"salt\" vectors](./images/vector-water.png)\n",
    "\n",
    "Source: https://github.com/grzenkom/do-androids-read/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d63fce",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Retrieval Augmented Generation (RAG)\n",
    "\n",
    "With RAG, documents can be stored as embeddings in a vector database, queried\n",
    "for based on semantic meaning, and then these relevant splits are passed into\n",
    "**model prompt via the context window**. LLM uses these text chunks from\n",
    "original documents to generate an answer.\n",
    "\n",
    "![Question Answering flow](images/langchain-qa-flow.jpeg)\n",
    "\n",
    "Source: https://python.langchain.com/docs/use_cases/question_answering/#overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97e1686",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## LangChain integrations\n",
    "\n",
    "1. [Catalog](https://integrations.langchain.com/llms)\n",
    "2. [Documentation](https://python.langchain.com/docs/integrations)\n",
    "\n",
    "![LangChain integrations](./images/langchain-integrations.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce7c79d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-29T18:39:47.648775Z",
     "start_time": "2023-08-29T18:39:47.644757Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## RAG step 1 - load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1e971853",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T11:36:24.628030Z",
     "start_time": "2023-09-01T11:36:05.148862Z"
    },
    "execution": {
     "iopub.execute_input": "2023-08-16T22:08:50.663435Z",
     "iopub.status.busy": "2023-08-16T22:08:50.662895Z",
     "iopub.status.idle": "2023-08-16T22:09:09.419282Z",
     "shell.execute_reply": "2023-08-16T22:09:09.417508Z",
     "shell.execute_reply.started": "2023-08-16T22:08:50.663380Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WikipediaLoader\n",
    "\n",
    "loader = WikipediaLoader(query=\"BiaÅ‚owieÅ¼a Forest\", lang=\"en\")\n",
    "bf_docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "040ddb4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T11:36:25.368017Z",
     "start_time": "2023-09-01T11:36:24.630942Z"
    },
    "execution": {
     "iopub.execute_input": "2023-08-16T22:09:09.424667Z",
     "iopub.status.busy": "2023-08-16T22:09:09.422729Z",
     "iopub.status.idle": "2023-08-16T22:09:10.085782Z",
     "shell.execute_reply": "2023-08-16T22:09:10.084546Z",
     "shell.execute_reply.started": "2023-08-16T22:09:09.424571Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    \"https://bpn.com.pl/index.php?option=com_content&task=view&id=651&Itemid=297&lang=en\"\n",
    ")\n",
    "bpn_page = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57986189",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-29T18:39:47.648775Z",
     "start_time": "2023-08-29T18:39:47.644757Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## RAG step 1 - load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d5ab6176",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T11:36:36.655795Z",
     "start_time": "2023-09-01T11:36:25.371219Z"
    },
    "execution": {
     "iopub.execute_input": "2023-08-16T22:08:50.663435Z",
     "iopub.status.busy": "2023-08-16T22:08:50.662895Z",
     "iopub.status.idle": "2023-08-16T22:09:09.419282Z",
     "shell.execute_reply": "2023-08-16T22:09:09.417508Z",
     "shell.execute_reply.started": "2023-08-16T22:08:50.663380Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# load some unreleated document to test the vector store later\n",
    "\n",
    "loader = WikipediaLoader(query=\"Kubeflow\", lang=\"en\")\n",
    "kf_docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e47197f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-29T18:39:47.648775Z",
     "start_time": "2023-08-29T18:39:47.644757Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## RAG step 2 - split documents into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ac9b0f97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T11:36:36.709465Z",
     "start_time": "2023-09-01T11:36:36.664824Z"
    },
    "execution": {
     "iopub.execute_input": "2023-08-16T22:09:10.089999Z",
     "iopub.status.busy": "2023-08-16T22:09:10.087364Z",
     "iopub.status.idle": "2023-08-16T22:09:10.228097Z",
     "shell.execute_reply": "2023-08-16T22:09:10.225802Z",
     "shell.execute_reply.started": "2023-08-16T22:09:10.089875Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500, chunk_overlap = 0\n",
    ")\n",
    "all_splits = text_splitter.split_documents(bf_docs + bpn_page + kf_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7740590d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-29T18:39:47.648775Z",
     "start_time": "2023-08-29T18:39:47.644757Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## RAG step 3 - calculate embeddings for text chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2e24add8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T11:36:37.515466Z",
     "start_time": "2023-09-01T11:36:36.713439Z"
    },
    "execution": {
     "iopub.execute_input": "2023-08-16T22:09:10.231405Z",
     "iopub.status.busy": "2023-08-16T22:09:10.230699Z",
     "iopub.status.idle": "2023-08-16T22:09:33.259577Z",
     "shell.execute_reply": "2023-08-16T22:09:33.258129Z",
     "shell.execute_reply.started": "2023-08-16T22:09:10.231350Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "hf_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "    model_kwargs={\n",
    "        \"device\": \"cpu\"\n",
    "    },\n",
    "    encode_kwargs={\n",
    "        \"normalize_embeddings\": False\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeabe23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-29T18:39:47.648775Z",
     "start_time": "2023-08-29T18:39:47.644757Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## RAG step 4 - store embeddings in a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dc27f47d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T11:36:52.875339Z",
     "start_time": "2023-09-01T11:36:37.517419Z"
    },
    "execution": {
     "iopub.execute_input": "2023-08-16T22:09:10.231405Z",
     "iopub.status.busy": "2023-08-16T22:09:10.230699Z",
     "iopub.status.idle": "2023-08-16T22:09:33.259577Z",
     "shell.execute_reply": "2023-08-16T22:09:33.258129Z",
     "shell.execute_reply.started": "2023-08-16T22:09:10.231350Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=all_splits, embedding=hf_embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab34f81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-29T18:39:47.648775Z",
     "start_time": "2023-08-29T18:39:47.644757Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## RAG step 4 - store embeddings in a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "39b07025",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T11:42:41.113926Z",
     "start_time": "2023-09-01T11:42:41.046503Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Kubeflow is an open-source platform for machine learning and MLOps on Kubernetes introduced by Googl',\n",
       "  0.5977725982666016),\n",
       " ('=== Kubeflow Pipelines for model training ===\\nOnce developed, models are trained in the Kubeflow Pip',\n",
       "  0.789579451084137),\n",
       " ('become among the top 2% of GitHub projects ever. Kubeflow 1.0 was released in March 2020 via a publi',\n",
       "  0.8031338453292847),\n",
       " ('=== KServe for model serving ===\\nThe KServe component (previously named KFServing) provides Kubernet',\n",
       "  0.81390780210495)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_splits = vector_store.similarity_search_with_score(\"kubeflow\", k=3)\n",
    "[(doc_split.page_content[:100], score) for doc_split, score in relevant_splits]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ee07d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-29T18:39:47.648775Z",
     "start_time": "2023-08-29T18:39:47.644757Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## RAG step 5 - initialize a Q&A chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4df87ac3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T11:12:45.525398Z",
     "start_time": "2023-09-01T11:12:45.059473Z"
    },
    "execution": {
     "iopub.execute_input": "2023-08-16T22:09:33.262533Z",
     "iopub.status.busy": "2023-08-16T22:09:33.261903Z",
     "iopub.status.idle": "2023-08-16T22:09:34.035364Z",
     "shell.execute_reply": "2023-08-16T22:09:34.034420Z",
     "shell.execute_reply.started": "2023-08-16T22:09:33.262483Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# the QA chain is constructed with the LLM model (loaded earlier)\n",
    "# and the embedding database\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=model, retriever=vector_store.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da2a814",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### `RetrievalQA` chain - processing steps\n",
    "\n",
    "1. query the vector database for document splits relevant to the question,\n",
    "2. pass the retrieved splits into the model prompt,\n",
    "3. have the LLM generate an answer based on original documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b9f19b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-29T18:39:47.648775Z",
     "start_time": "2023-08-29T18:39:47.644757Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## RAG step 6 - use Q&A chain to query the loaded documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "edbc4533",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T11:13:05.320130Z",
     "start_time": "2023-09-01T11:12:45.527488Z"
    },
    "execution": {
     "iopub.execute_input": "2023-08-16T22:09:34.038393Z",
     "iopub.status.busy": "2023-08-16T22:09:34.037898Z",
     "iopub.status.idle": "2023-08-16T22:10:09.259053Z",
     "shell.execute_reply": "2023-08-16T22:10:09.257612Z",
     "shell.execute_reply.started": "2023-08-16T22:09:34.038357Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> White  Tower.\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What does the name 'Bialowieza' mean in English?\"\n",
    "\n",
    "qa_chain(f\"Provide brief answers, use 10 words or less. {question}\")[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e644748",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T11:13:33.014687Z",
     "start_time": "2023-09-01T11:13:05.322406Z"
    },
    "execution": {
     "iopub.execute_input": "2023-08-16T22:10:09.261416Z",
     "iopub.status.busy": "2023-08-16T22:10:09.260834Z",
     "iopub.status.idle": "2023-08-16T22:10:46.003982Z",
     "shell.execute_reply": "2023-08-16T22:10:45.998835Z",
     "shell.execute_reply.started": "2023-08-16T22:10:09.261366Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> 4  km  long,  starts  at  Przed  Kosym  Mostem  depot.\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What's the length of the Tsar's Trail and where does it begin?\"\n",
    "\n",
    "qa_chain(f\"Provide brief answers, use 10 words or less. {question}\")[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796e380a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## No more hallucinations then?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f7547af8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T11:13:52.625766Z",
     "start_time": "2023-09-01T11:13:33.017777Z"
    },
    "execution": {
     "iopub.execute_input": "2023-08-16T22:10:46.006264Z",
     "iopub.status.busy": "2023-08-16T22:10:46.005570Z",
     "iopub.status.idle": "2023-08-16T22:11:22.084775Z",
     "shell.execute_reply": "2023-08-16T22:11:22.082796Z",
     "shell.execute_reply.started": "2023-08-16T22:10:46.006221Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> No,  it  is  known  for  its  undergrowth  plants  and  animal  trails.\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Is Bialowieza Forest famous for its walking trails?\"\n",
    "\n",
    "qa_chain(f\"Provide brief answers, use 10 words or less. {question}\")[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9a066a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Next steps\n",
    "\n",
    "1. Other loaders\n",
    "    - PDF files\n",
    "    - slide decks\n",
    "    - Google Sites\n",
    "    - files in Google Drive\n",
    "2. Conversational interface\n",
    "3. Memory\n",
    "4. Larger model\n",
    "5. GPU processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c569ce",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Links\n",
    "\n",
    "### Overview\n",
    "\n",
    "- [How OpenAI trained ChatGPT](https://blog.quastor.org/p/openai-trained-chatgpt)\n",
    "    - ðŸŽ¥ [State of GPT | Andrej Karpathy](https://www.youtube.com/watch?v=s6zNXZaIiiI) \n",
    "- [Catching up on the weird world of LLMs](https://simonwillison.net/2023/Aug/3/weird-world-of-llms)\n",
    "- [What We Know About LLMs  (Primer)](https://willthompson.name/what-we-know-about-llms-primer) \n",
    "- [The Many Ways that Digital Minds Can Know](https://moultano.wordpress.com/2023/06/28/the-many-ways-that-digital-minds-can-know)\n",
    "\n",
    "### Tutorials\n",
    "\n",
    "- [Running a Hugging Face Large Language Model (LLM) locally on my laptop](https://www.markhneedham.com/blog/2023/06/23/hugging-face-run-llm-model-locally-laptop)\n",
    "- [Why You (Probably) Donâ€™t Need to Fine-tune an LLM](https://www.tidepool.so/2023/08/17/why-you-probably-dont-need-to-fine-tune-an-llm/)\n",
    "\n",
    "### Challenges\n",
    "\n",
    "- [Open challenges in LLM research](https://huyenchip.com/2023/08/16/llm-research-open-challenges.html) \n",
    "- [OWASP Top 10 for Large Language Model Applications](https://owasp.org/www-project-top-10-for-large-language-model-applications) \n",
    "\n",
    "### Skepticism\n",
    "\n",
    "- [Anti-hype LLM reading list](https://gist.github.com/veekaybee/be375ab33085102f9027853128dc5f0e)\n",
    "- [What if Generative AI turned out to be a Dud?](https://garymarcus.substack.com/p/what-if-generative-ai-turned-out)\n",
    "    - And [Marcus on AI](https://garymarcus.substack.com) in general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbec57e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/roche-logo-blue.png\" alt=\"Roche logo\" style=\"float: right;\" width=\"150\" />\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "\n",
    "# Doing now what patients need next\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "\n",
    "TODO: add go.roche.com links to the GitHub repository"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
