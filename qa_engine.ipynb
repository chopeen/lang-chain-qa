{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50d8f709-adfe-4c4f-88dc-2362442c3f62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T14:45:38.845348Z",
     "iopub.status.busy": "2023-08-11T14:45:38.844963Z",
     "iopub.status.idle": "2023-08-11T14:45:40.846645Z",
     "shell.execute_reply": "2023-08-11T14:45:40.845847Z",
     "shell.execute_reply.started": "2023-08-11T14:45:38.845312Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain import PromptTemplate, LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dfb1f13-fce3-4237-b62d-6ebf60f9b372",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T13:28:11.828122Z",
     "iopub.status.busy": "2023-08-11T13:28:11.827248Z",
     "iopub.status.idle": "2023-08-11T13:28:11.839879Z",
     "shell.execute_reply": "2023-08-11T13:28:11.837671Z",
     "shell.execute_reply.started": "2023-08-11T13:28:11.828046Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3609189d-f8af-4108-bdf3-d236dc962148",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T14:39:21.566172Z",
     "iopub.status.busy": "2023-08-11T14:39:21.565183Z",
     "iopub.status.idle": "2023-08-11T14:39:55.992784Z",
     "shell.execute_reply": "2023-08-11T14:39:55.991940Z",
     "shell.execute_reply.started": "2023-08-11T14:39:21.566112Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n",
      "Device has 1 GPUs available. Provide device={deviceId} to `from_model_id` to use availableGPUs for execution. deviceId is -1 (default) for CPU and can be a positive integer associated with CUDA device id.\n"
     ]
    }
   ],
   "source": [
    "model_id, task = \"lmsys/fastchat-t5-3b-v1.0\", \"text2text-generation\"\n",
    "\n",
    "# the model will be downloaded on first use, if not cached in ~/.cache/huggingface/hub/\n",
    "\n",
    "model = HuggingFacePipeline.from_model_id(\n",
    "    model_id=model_id,\n",
    "    task=task,\n",
    "    model_kwargs={\n",
    "        \"temperature\": 0,\n",
    "        \"max_length\": 1000\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92648678-bf7d-460f-bac7-6f6df210efcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T14:33:55.227586Z",
     "iopub.status.busy": "2023-08-11T14:33:55.226313Z",
     "iopub.status.idle": "2023-08-11T14:33:55.238251Z",
     "shell.execute_reply": "2023-08-11T14:33:55.236587Z",
     "shell.execute_reply.started": "2023-08-11T14:33:55.227504Z"
    }
   },
   "outputs": [],
   "source": [
    "template_text = \"\"\"\n",
    "{question}\n",
    "\"\"\"\n",
    "template = PromptTemplate(template=template_text, input_variables=[\"question\"])\n",
    "llm_chain = LLMChain(prompt=template, llm=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a65b6e81-1153-4ca8-be9a-3b2ebf1f6668",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T14:10:59.925561Z",
     "iopub.status.busy": "2023-08-11T14:10:59.924711Z",
     "iopub.status.idle": "2023-08-11T14:12:14.136877Z",
     "shell.execute_reply": "2023-08-11T14:12:14.135659Z",
     "shell.execute_reply.started": "2023-08-11T14:10:59.925484Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/grzenkom/.pyenv/versions/3.10.12/envs/lang-chain-qa-env/lib/python3.10/site-packages/transformers/generation/utils.py:1270: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<pad> Sheryl  Crow  is  an  American  singer,  songwriter,  and  actress.  She  is  best  known  for  her  role  as  the  lead  singer  and  lead  guitarist  of  the  rock  band  The  Band wagon,  and  for  her  role  as  the  lead  singer  and  lead  guitarist  of  the  alternative  rock  band  The  Mamas  and  the  Papas.  Crow  has  also  been  a  member  of  the  band  The  Mamas  and  the  Papas  since  its  formation  in  1995.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain(\"Who is Sheryl Crow?\")[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bcb45e0-cfbb-4a52-a9f8-51aa9958fe30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T14:33:59.170363Z",
     "iopub.status.busy": "2023-08-11T14:33:59.169157Z",
     "iopub.status.idle": "2023-08-11T14:34:07.249923Z",
     "shell.execute_reply": "2023-08-11T14:34:07.248200Z",
     "shell.execute_reply.started": "2023-08-11T14:33:59.170266Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/grzenkom/.pyenv/versions/3.10.12/envs/lang-chain-qa-env/lib/python3.10/site-packages/transformers/generation/utils.py:1270: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<pad> Sheryl  Crow  is  57  years  old.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain(\"How old is Sheryl Crow?\")[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eff06ea-4b51-4f7f-b2ee-97feedaaca87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T14:34:11.672745Z",
     "iopub.status.busy": "2023-08-11T14:34:11.672235Z",
     "iopub.status.idle": "2023-08-11T14:34:11.678579Z",
     "shell.execute_reply": "2023-08-11T14:34:11.677268Z",
     "shell.execute_reply.started": "2023-08-11T14:34:11.672714Z"
    }
   },
   "outputs": [],
   "source": [
    "template_text = \"\"\"\n",
    "{question}\n",
    "Explain step by step.\n",
    "\"\"\"\n",
    "template = PromptTemplate(template=template_text, input_variables=[\"question\"])\n",
    "llm_chain = LLMChain(prompt=template, llm=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbd976c3-a02a-400a-a922-65b2f379be68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T14:34:16.839144Z",
     "iopub.status.busy": "2023-08-11T14:34:16.838527Z",
     "iopub.status.idle": "2023-08-11T14:34:45.918642Z",
     "shell.execute_reply": "2023-08-11T14:34:45.916845Z",
     "shell.execute_reply.started": "2023-08-11T14:34:16.839112Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> Sheryl Crow is a singer and songwriter who was born on February 28, 1969. So, Sheryl Crow is currently 57 years old. To find her age, you would need to subtract her age from her birth date. So, the answer is 57 years old.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain(\"How old is Sheryl Crow?\")[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22b7fb6c-59d8-457b-a79a-9a2aa9319e8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T14:35:38.220048Z",
     "iopub.status.busy": "2023-08-11T14:35:38.219582Z",
     "iopub.status.idle": "2023-08-11T14:35:52.398022Z",
     "shell.execute_reply": "2023-08-11T14:35:52.397100Z",
     "shell.execute_reply.started": "2023-08-11T14:35:38.220002Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> Sheryl Crow was born in 1969. So, in 2023, Sheryl Crow would be 69 years old. So the answer is 69.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain(\"The year is 2023. How old is Sheryl Crow?\")[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a492a213-7be9-4014-86f5-b9b83939b47b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T14:45:46.805596Z",
     "iopub.status.busy": "2023-08-11T14:45:46.805085Z",
     "iopub.status.idle": "2023-08-11T14:46:02.899758Z",
     "shell.execute_reply": "2023-08-11T14:46:02.897867Z",
     "shell.execute_reply.started": "2023-08-11T14:45:46.805564Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WikipediaLoader\n",
    "\n",
    "loader = WikipediaLoader(\"Sheryl_Crow\")\n",
    "document = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c9045d0-044a-4e30-a1ed-a9eee09e9fd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T14:46:08.857599Z",
     "iopub.status.busy": "2023-08-11T14:46:08.857093Z",
     "iopub.status.idle": "2023-08-11T14:46:08.886648Z",
     "shell.execute_reply": "2023-08-11T14:46:08.884446Z",
     "shell.execute_reply.started": "2023-08-11T14:46:08.857558Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://python.langchain.com/docs/use_cases/question_answering/#step-1-load\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 0)\n",
    "all_splits = text_splitter.split_documents(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75c4bc61-b25a-42fb-af4b-24313ea30677",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T15:02:17.050572Z",
     "iopub.status.busy": "2023-08-11T15:02:17.050143Z",
     "iopub.status.idle": "2023-08-11T15:02:17.059913Z",
     "shell.execute_reply": "2023-08-11T15:02:17.058779Z",
     "shell.execute_reply.started": "2023-08-11T15:02:17.050536Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/chroma-core/chroma/blob/main/chromadb/__init__.py#L57\n",
    "__import__(\"pysqlite3\")\n",
    "sys.modules[\"sqlite3\"] = sys.modules.pop(\"pysqlite3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6cb657d-4234-416d-a5b2-c76609e8ce5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T15:02:21.408711Z",
     "iopub.status.busy": "2023-08-11T15:02:21.408133Z",
     "iopub.status.idle": "2023-08-11T15:02:22.646788Z",
     "shell.execute_reply": "2023-08-11T15:02:22.645559Z",
     "shell.execute_reply.started": "2023-08-11T15:02:21.408658Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'chromadb' has no attribute 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 15\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# https://integrations.langchain.com/embeddings\u001b[39;00m\n\u001b[1;32m      5\u001b[0m hf_embeddings \u001b[38;5;241m=\u001b[39m HuggingFaceEmbeddings(\n\u001b[1;32m      6\u001b[0m     model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence-transformers/all-mpnet-base-v2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     model_kwargs\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     }\n\u001b[1;32m     13\u001b[0m )\n\u001b[0;32m---> 15\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_splits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_embeddings\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/lang-chain-qa-env/lib/python3.10/site-packages/langchain/vectorstores/chroma.py:603\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    601\u001b[0m texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    602\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m--> 603\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/lang-chain-qa-env/lib/python3.10/site-packages/langchain/vectorstores/chroma.py:558\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_texts\u001b[39m(\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28mcls\u001b[39m: Type[Chroma],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    538\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Chroma:\n\u001b[1;32m    539\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a Chroma vectorstore from a raw documents.\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \n\u001b[1;32m    541\u001b[0m \u001b[38;5;124;03m    If a persist_directory is specified, the collection will be persisted there.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;124;03m        Chroma: Chroma vectorstore.\u001b[39;00m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 558\u001b[0m     chroma_collection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m     chroma_collection\u001b[38;5;241m.\u001b[39madd_texts(texts\u001b[38;5;241m=\u001b[39mtexts, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, ids\u001b[38;5;241m=\u001b[39mids)\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m chroma_collection\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/lang-chain-qa-env/lib/python3.10/site-packages/langchain/vectorstores/chroma.py:118\u001b[0m, in \u001b[0;36mChroma.__init__\u001b[0;34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001b[0m\n\u001b[1;32m    116\u001b[0m     _client_settings\u001b[38;5;241m.\u001b[39mpersist_directory \u001b[38;5;241m=\u001b[39m persist_directory\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     _client_settings \u001b[38;5;241m=\u001b[39m \u001b[43mchromadb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241m.\u001b[39mSettings()\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_settings \u001b[38;5;241m=\u001b[39m _client_settings\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client \u001b[38;5;241m=\u001b[39m chromadb\u001b[38;5;241m.\u001b[39mClient(_client_settings)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'chromadb' has no attribute 'config'"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# https://integrations.langchain.com/embeddings\n",
    "hf_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "    model_kwargs={\n",
    "        'device': 'cpu'\n",
    "    },\n",
    "    encode_kwargs={\n",
    "        'normalize_embeddings': False\n",
    "    }\n",
    ")\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=hf_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9749fa9-ab7a-4cbe-b303-4fa5f0671c25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
